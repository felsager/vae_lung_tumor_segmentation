{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation of Medical Scans using Variational VAE's - Part 1/3\n",
    "This series of notebooks enables reproduceability of our final models and testing results.\n",
    "\n",
    "The first notebook goes through the process of preparing/preprocessing and understanding our data.\n",
    "\n",
    "We import some necessary libraries, and check if our GPU is available, while also retrieving some system stats. We need a lot of RAM, because our selected datasets are very large. We setup up some global constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "NVIDIA GeForce GTX 1070\n",
      "CUDA version: 11.7\n",
      "RAM: 16.74GB\n"
     ]
    }
   ],
   "source": [
    "# For ML\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torchvision.transforms as Transform\n",
    "\n",
    "# For reading raw data.\n",
    "import json\n",
    "import nibabel as nib\n",
    "\n",
    "# For displaying and evaluating results.\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# For monitoring resource-usage and progress.\n",
    "from tqdm import tqdm # Install ipywidgets to remove warning.\n",
    "import psutil\n",
    "from os.path import join, exists\n",
    "\n",
    "\n",
    "root_dir = '../' # Location of project, relative to the working directory.\n",
    "raw_data_dir = join(root_dir, 'raw_data')\n",
    "prep_data_dir = join(root_dir, 'prep_data')\n",
    "losses_dir = join(root_dir, 'losses')\n",
    "models_dir = join(root_dir, 'saved_models')\n",
    "checkpoint_dir = join(root_dir, 'checkpoints')\n",
    "\n",
    "\n",
    "# Setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('CUDA version:', torch.version.cuda)\n",
    "\n",
    "available_ram = round(psutil.virtual_memory()[0]/1000000000,2)\n",
    "print('RAM: ' + str(available_ram) + 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We preprocess and format datasets from raw data for each specified organ, using the above function. We save progress after each organ is completed. Can be interrupted and resumed at any time, and accounts for progress, which has already been made. We define a function which loads and stores our data in the proper formatting. As the datasets are huge and have to concatenate each set of 240 slices to the previous, we monitor progress and RAM-usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(organ, type, resolution):\n",
    "    with open(join(raw_data_dir, organ, 'dataset.json')) as f:\n",
    "        manifest = json.load(f)['training']\n",
    "    \n",
    "    bar = tqdm(total=len(manifest))\n",
    "    bar.set_description('Prepping ' + organ + ' ' + type + 's')\n",
    "    \n",
    "    resize = Transform.Resize((resolution, resolution))\n",
    "\n",
    "    try: \n",
    "        images = torch.zeros((0, resolution, resolution))\n",
    "\n",
    "        for entry in manifest:\n",
    "            bar.set_postfix(**{'RAM':round(psutil.virtual_memory()[3]/10e8, 2)})\n",
    "            bar.update()\n",
    "\n",
    "            nii_img = nib.load(join(raw_data_dir, organ, entry[type][2:]))\n",
    "\n",
    "            # Convert to numpy array, then pytorch tensor.\n",
    "            nii_data = Tensor(nii_img.get_fdata())\n",
    "            \n",
    "            # Scale between 0 and 1. Try -1 and 1?\n",
    "            nii_data -= nii_data.min()\n",
    "            nii_data /= nii_data.max()\n",
    "\n",
    "            nii_data = nii_data.permute(2, 0, 1) # (slice, rows, columns)\n",
    "            nii_data = resize(nii_data)\n",
    "            images = torch.cat((images, nii_data), 0)\n",
    "        \n",
    "        torch.save(images, join(prep_data_dir, organ + '_' + type + '_slices_' + str(resolution) + '.pt'))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Manually stopped.')\n",
    "    \n",
    "    bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the preprocessor function for the organs, we wish to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already prepped.\n"
     ]
    }
   ],
   "source": [
    "lod = 2**8          # Level of detail.\n",
    "resolution = lod    # 2**8 = 256\n",
    "do_prep = False     # Toggle to prep data.\n",
    "\n",
    "organs = ['spleen'] #,'colon','pancreas','lung','liver']\n",
    "\n",
    "if do_prep:\n",
    "    for organ in organs:\n",
    "        prep_data(organ,'image',resolution)\n",
    "        prep_data(organ,'label',resolution)\n",
    "else:\n",
    "    print('Data already prepped.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9f82d0d752eb34e678ed91836faafc818af014405bd67d0435880e47f8c111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
