{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation of Medical Scans using Variational VAE's\n",
    "This notebook goes through the process of creating a pytorch-compatible dataset, and setting up a model for segmentation of tumors in various organs. It enables reproduceability of our final model and testing results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "We import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ML\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as U\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "\n",
    "# For reading raw data.\n",
    "import json\n",
    "import nibabel as nib\n",
    "\n",
    "# For displaying and evaluating results.\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# For monitoring resource-usage and progress.\n",
    "from tqdm import tqdm\n",
    "import os, sys, psutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if GPU is available and retrieve some system stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "NVIDIA GeForce GTX 1070\n",
      "CUDA version: 11.7\n",
      "RAM: 16.74GB\n"
     ]
    }
   ],
   "source": [
    "# Setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('CUDA version:', torch.version.cuda)\n",
    "\n",
    "available_ram = round(psutil.virtual_memory()[0]/1000000000,2)\n",
    "print('RAM: ' + str(available_ram) + 'GB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure, we are in the correct working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/nv/Storage/Data-Science/vae_lung_tumor_segmentation/net_md\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up some global constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './' # Location of project, relative to the working directory.\n",
    "raw_data_dir = os.path.join(root_dir, 'data', 'raw_data')\n",
    "aug_data_dir = os.path.join(root_dir, 'data', 'aug_data')\n",
    "model_dir = os.path.join(root_dir, 'model')\n",
    "stats_dir = os.path.join(root_dir, 'stats')\n",
    "output_dir = os.path.join(root_dir, 'output')\n",
    "progress_file = os.path.join(stats_dir,'progression.json')\n",
    "\n",
    "organs = ['spleen', 'colon', 'lung']\n",
    "d = 256 # New dimensions (width and height) of datapoints.\n",
    "num_chunks = 16 # Number of chunks to divide our data into.\n",
    "\n",
    "# Data transforms.\n",
    "resize_transform = T.Resize((d, d))\n",
    "rand_rot_transform = T.RandomRotation(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup a folder structure for our data - both raw and preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(raw_data_dir):\n",
    "    os.mkdir(raw_data_dir)\n",
    "    for organ in organs:\n",
    "        os.mkdir(os.path.join(raw_data_dir, organ))\n",
    "        \n",
    "if not os.path.exists(aug_data_dir):\n",
    "    os.makedirs(aug_data_dir)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(aug_data_dir)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "if not os.path.exists(stats_dir):\n",
    "    os.makedirs(stats_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `raw_data/` sub-directories for each organ has to be populated manually using the unzipped files from [medicaldecathlon.com](https://drive.google.com/drive/folders/1HqEgzS8BV2c7xYNrZdEAnrHk7osJJ--2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load current progress, as to not repeat work, which has already been completed, when running the entire notebook at once. The progress flags are stored externally in `progression.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(progress_file,'r') as f:\n",
    "    progression = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function which loads and stores our data in the proper formatting. As the datasets are huge, we monitor progress and RAM-usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(organ, training_paths, data_tensor, progress):\n",
    "    for _, path in enumerate(training_paths):\n",
    "        progress.set_postfix(**{'RAM':round(psutil.virtual_memory()[3]/1000000000,2)})\n",
    "        progress.update()\n",
    "\n",
    "        # Get path to images - removed dot in path from json-file.\n",
    "        nii_img = nib.load(os.path.join(raw_data_dir,organ + path['image'][1:]))\n",
    "        \n",
    "        nii_data = nii_img.get_fdata()\n",
    "        nii_data = Tensor(nii_img.get_fdata())\n",
    "        \n",
    "        # Ensure scale [0; 1]\n",
    "        nii_data -= nii_data.min()\n",
    "        nii_data /= nii_data.max() # Are the max the same in every data point?\n",
    "        nii_data = nii_data.permute(2, 0, 1) # Shape: (slice, rows, columns)\n",
    "        nii_data = resize_transform(nii_data)\n",
    "        data_tensor = torch.cat((data_tensor, nii_data), 0)\n",
    "        \n",
    "    torch.save(data_tensor, os.path.join(aug_data_dir,organ+'_slices_unaugmented.pt'))\n",
    "    progress.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process and format datasets from raw data for each organ, using the above function. We save progress after each organ is completed. Can be interrupted and resumed at any time, and accounts for progress, which has already been made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spleen set has already been loaded.\n",
      "The colon set has already been loaded.\n",
      "The lung set has already been loaded.\n"
     ]
    }
   ],
   "source": [
    "for organ in organs:\n",
    "    if not progression['loaded'][organ]:\n",
    "\n",
    "        path = os.path.join(raw_data_dir,organ,'dataset.json')\n",
    "        with open(path) as f:\n",
    "            data_set = json.load(f)\n",
    "        training_paths = data_set['training']\n",
    "\n",
    "        data_tensor = torch.zeros((0, d, d))\n",
    "        total_paths = len(training_paths)\n",
    "\n",
    "        progress = tqdm(total=total_paths)\n",
    "        progress.set_description(f'%s' % organ)\n",
    "\n",
    "        try: \n",
    "            augment_data(organ, training_paths, data_tensor, progress)\n",
    "            print('The ' + organ + ' was successfully loaded.')\n",
    "\n",
    "            # Change state of progression.json\n",
    "            progression['loaded'][organ] = True\n",
    "            with open(progress_file, \"w\") as f: \n",
    "                json.dump(progression, f, indent=4)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print ('Manually stopped.\\nOrgan: ' + organ + ' was not saved.')\n",
    "            progress.close()\n",
    "            break\n",
    "    else:\n",
    "        print('The ' + organ + ' set has already been loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are so large, that we need to split them into smaller chunks. We first initialize empty chunks, and fill them with augmented data from each organ, evenly split amongst the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation and chunking already completed.\n"
     ]
    }
   ],
   "source": [
    "if not progression['augmented']:\n",
    "    \n",
    "    for n in range(num_chunks):\n",
    "        chunk = torch.zeros(0, d, d)\n",
    "        torch.save(chunk, os.path.join(aug_data_dir, f'unaugmented_chunk_{n}.pt'))\n",
    "\n",
    "    progress = tqdm(total=len(organs)*num_chunks)\n",
    "    progress.set_description(f'Augmentation')\n",
    "    \n",
    "    try:\n",
    "        for organ in organs:\n",
    "            data = torch.load(os.path.join(aug_data_dir,organ+ '_slices_unaugmented.pt'))\n",
    "            N = data.shape[0]\n",
    "            idx = torch.randperm(N)\n",
    "            data = data[idx]\n",
    "            split_idx = int(N/num_chunks)\n",
    "            \n",
    "            for n in range(num_chunks):\n",
    "                path = os.path.join(aug_data_dir, f'unaugmented_chunk_{n}.pt')\n",
    "                chunk = torch.load(path)\n",
    "                chunk = torch.cat((chunk, data[n*split_idx:(n+1)*split_idx]), 0)\n",
    "                torch.save(chunk, path)\n",
    "                progress.update()\n",
    "\n",
    "        print('Augmentation was successful.')\n",
    "\n",
    "        # Change state of progression.json\n",
    "        progression['augmented'] = True\n",
    "        with open(progress_file, \"w\") as f: \n",
    "            json.dump(progression, f, indent=4)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print ('Manually stopped.\\nChunk ' + str(n) + ' was not saved.')\n",
    "        progress.close()\n",
    "        \n",
    "else:\n",
    "    print('Data augmentation and chunking already completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Management\n",
    "We define a custom dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating Model Architecture\n",
    "We define our model architecture for the variational autoencoder, which consists of an encoder and a decoder. We start with the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, imageShape, firstFilterCount, act, layerwise=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.act = act\n",
    "        self.imageShape = imageShape\n",
    "        self.firstFilterCount = firstFilterCount\n",
    "        self.layerwise = layerwise\n",
    "\n",
    "        self.convDownsamplingLayers = torch.nn.ModuleList()\n",
    "        self.muEncodingLayers = torch.nn.ModuleList()\n",
    "        self.logVarEncodingLayers = torch.nn.ModuleList()\n",
    "\n",
    "        for level in range(int(np.log2(self.imageShape[1])-1)):\n",
    "            if level == 0:\n",
    "                self.convDownsamplingLayers.append(torch.nn.Conv2d(in_channels=self.imageShape[0], out_channels=firstFilterCount, kernel_size=4, stride=2, padding=1))\n",
    "            else:\n",
    "                self.convDownsamplingLayers.append(torch.nn.Conv2d(in_channels=firstFilterCount * 2**(level - 1), out_channels=firstFilterCount * 2**(level), kernel_size=4, stride=2, padding=1))\n",
    "\n",
    "            features, code_length = self.firstFilterCount * 2 ** (level + 2), int(2 ** (level + 2))\n",
    "            self.muEncodingLayers.append(torch.nn.Linear(in_features=features, out_features=code_length))\n",
    "            self.logVarEncodingLayers.append(torch.nn.Linear(in_features=features, out_features=code_length))\n",
    "    \n",
    "    def sample(self, mu, logVar):\n",
    "        # Reparameterize:\n",
    "        std = torch.exp(0.5 * logVar)\n",
    "        epsilon = torch.randn_like(std)\n",
    "        z = mu + std * epsilon\n",
    "        return z\n",
    "    \n",
    "    def encode(self, x, scale):\n",
    "        for layer in range(scale):\n",
    "            x = self.convDownsamplingLayers[layer](x)\n",
    "\n",
    "        # Define layer based on given scale.\n",
    "        x = self.convDownsamplingLayers[scale](x)\n",
    "\n",
    "        # Gaussian prior.\n",
    "        shape = x.shape\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        mu = (self.muEncodingLayers[scale](x))\n",
    "        logVar = (self.logVarEncodingLayers[scale](x))\n",
    "        \n",
    "        return mu, logVar, shape\n",
    "    \n",
    "    def forward(self, x, scale):\n",
    "        mu, logVar, shape = self.encode(x, scale)\n",
    "        z = self.sample(mu, logVar)\n",
    "        return z, mu, logVar, shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the decoder architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, imageShape, firstFilterCount, act, layerwise=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.act = act\n",
    "        self.imageShape = imageShape\n",
    "        self.firstFilterCount = firstFilterCount\n",
    "        self.layerwise = layerwise\n",
    "\n",
    "        self.convUpsamplingLayers = torch.nn.ModuleList()\n",
    "        self.zDecodingLayers = torch.nn.ModuleList()\n",
    "\n",
    "        for level in range(int(np.log2(self.imageShape[1])-1)):\n",
    "            if level == 0:\n",
    "                self.convUpsamplingLayers.append(torch.nn.ConvTranspose2d(in_channels=firstFilterCount, out_channels=self.imageShape[0], kernel_size=4, stride=2, padding=1))\n",
    "            else:\n",
    "                self.convUpsamplingLayers.append(torch.nn.ConvTranspose2d(in_channels=int(firstFilterCount * 2**(level)), out_channels=int(firstFilterCount * 2**(level - 1)), kernel_size=4, stride=2, padding=1))\n",
    "            features, code_length = self.firstFilterCount * 2 ** (level + 2), int(2 ** (level + 2))\n",
    "            self.zDecodingLayers.append(torch.nn.Linear(in_features=code_length, out_features=features))\n",
    "    \n",
    "    def decode(self, z, scale, shape):\n",
    "        x = self.act(self.zDecodingLayers[scale](z)).reshape(shape)\n",
    "        \n",
    "        # Transpose Convolutions\n",
    "        for layer in range(scale):\n",
    "            x = self.act(self.convUpsamplingLayers[scale-layer](x))\n",
    "        x = self.convUpsamplingLayers[0](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, z, scale, shape, detach=False):\n",
    "        if detach:\n",
    "            z = z.detach()\n",
    "        x = self.decode(z, scale, shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use these two in combination to create our variational autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, imageShape, firstFilterCount, act, layerwise=True):\n",
    "        super(VAE, self).__init__()\n",
    "        self.act = act\n",
    "        self.imageShape = imageShape\n",
    "        self.firstFilterCount = firstFilterCount\n",
    "        self.layerwise = layerwise\n",
    "\n",
    "        self.encoder = Encoder(imageShape=imageShape, firstFilterCount=firstFilterCount, act=act, layerwise=layerwise)\n",
    "        self.decoder = Decoder(imageShape=imageShape, firstFilterCount=firstFilterCount, act=act, layerwise=layerwise)\n",
    "        self.decoder_segmentation = Decoder(imageShape=imageShape, firstFilterCount=firstFilterCount, act=act, layerwise=layerwise)\n",
    "\n",
    "    def forward(self, x, lod, printCode=False):\n",
    "        lod = lod - 2\n",
    "        z, mu, logVar, shape = self.encoder.forward(x, lod)\n",
    "        x_reconstructed = torch.sigmoid(self.decoder.forward(z, lod, shape))\n",
    "        x_segmentation = torch.sigmoid(self.decoder_segmentation.forward(z, lod, shape, detach=True))\n",
    "        if printCode:\n",
    "            print(z)\n",
    "        return ((x_reconstructed, mu, logVar), x_segmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Defining Training- and Evaluation Routines\n",
    "We define a class, which contain our testing routine, checkpoint management, evaluation routine, and some utility functions. This will allow us to easily run tests with different hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test():\n",
    "    def __init__(self, model, dir, load, optimizer, criterions, iou_thresh):\n",
    "        self.model = model\n",
    "        self.dir = dir\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.criterions = criterions\n",
    "        self.io_thresh = iou_thresh\n",
    "        \n",
    "        if load: \n",
    "            self.load_checkpoint(os.path.join(self.dir, 'checkpoint.pt'))\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "    \n",
    "    def load_checkpoint(self, path):\n",
    "        cp = torch.load(path)\n",
    "        self.model.load_state_dict(cp['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(cp['optimizer_state_dict'])\n",
    "        \n",
    "        for state in self.optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if torch.is_tensor(v):\n",
    "                    state[k] = v.cuda()\n",
    "\n",
    "    def save_checkpoint(self):\n",
    "        path = os.path.join(self.dir, 'checkpoint.pt')\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "        }, path)\n",
    "\n",
    "    def train(self, dataloader, epochs, lod, print_at=10):\n",
    "        for epoch in range(epochs):\n",
    "            batch_count = 0\n",
    "            losses = np.array([0] * len(self.criterions), dtype=np.float32)\n",
    "\n",
    "            for batch in dataloader:\n",
    "                print(np.shape(batch))\n",
    "                y = self.model.forward(batch['x'].to(self.device), lod)\n",
    "\n",
    "                # Backpropagation\n",
    "                self.model.zero_grad()\n",
    "                for i, value in enumerate(zip(y, self.criterions, batch)):\n",
    "                    output, criterion, key = value\n",
    "                    loss = criterion(output, batch[key].to(self.device))\n",
    "                    loss.backward()\n",
    "                    losses[i] += loss\n",
    "\n",
    "                self.optimizer.step()\n",
    "                batch_count += 1\n",
    "\n",
    "            if ((epoch % print_at) == 0):\n",
    "                losses = losses / batch_count\n",
    "                print('Epoch: ' + epoch, 'Reconst/kld loss: ' + losses[0], \n",
    "                      'Seg loss: ' + losses[1])\n",
    "\n",
    "    def IoU(self, label, reconst):\n",
    "        \"\"\"Calculates the IoU metric and returns the result within (0, 1).\"\"\"\n",
    "        i = ((label >= self.iou_thresh) & (reconst >= self.iou_thresh)) * 1.0\n",
    "        u = ((label >= self.iou_thresh) | (reconst >= self.iou_thresh)) * 1.0\n",
    "        return i.sum() / u.sum() / label.shape[0]\n",
    "\n",
    "    def evaluate(self, dataloader, lod):\n",
    "        batch_count = 0\n",
    "        losses = np.array([0] * len(self.criterions), dtype=np.float32)\n",
    "        iou = 0\n",
    "        for batch in dataloader:\n",
    "            y = self.model.forward(batch['x'].to(self.device), lod)\n",
    "\n",
    "            for i, value in enumerate(zip(y, self.criterions, batch)):\n",
    "                output, criterion, key = value\n",
    "                loss = criterion(output, batch[key].to(self.device))\n",
    "                losses[i] += loss\n",
    "            \n",
    "            iou += self.IoU(batch['t'].to(self.device), y[1])\n",
    "            batch_count += 1\n",
    "        \n",
    "        losses /= batch_count\n",
    "        iou /= batch_count\n",
    "        print('Reconst/kld loss:', losses[0], 'Seg loss:', losses[1], 'IoU:', iou)\n",
    "    \n",
    "    def reconstruct(self, dataloader, lod, count):\n",
    "        batch = next(iter(dataloader))\n",
    "        count = min(count, len(batch['x']))\n",
    "        x = batch['x'][:count].to(self.device)\n",
    "        t = batch['t'][:count].to(self.device)\n",
    "        y = self.model.forward(x, lod)\n",
    "        x_reconst = y[0][0]\n",
    "        x_segment = y[1]\n",
    "        return x, t, x_reconst, x_segment\n",
    "\n",
    "    def save_reconst(self, dataloader, lod, count, output_dir):\n",
    "        x_ins, t_ins, x_outs, t_outs = self.reconstruct(dataloader, lod, count)\n",
    "        x_ins = x_ins.detach().cpu().numpy()\n",
    "        t_ins = t_ins.detach().cpu().numpy()\n",
    "        x_outs = x_outs.detach().cpu().numpy()\n",
    "        t_outs = t_outs.detach().cpu().numpy()\n",
    "        \n",
    "        for i, value in enumerate(zip(x_ins, t_ins, x_outs, t_outs)):\n",
    "            x_in, t_in, x_out, t_out = value\n",
    "\n",
    "            x = np.stack([x_in] * 3, axis=0).squeeze().transpose((1, 2, 0))\n",
    "            t = np.stack([t_in] * 3, axis=0).squeeze().transpose((1, 2, 0))\n",
    "            mask = t[..., 0] > self.iouThreshold\n",
    "\n",
    "            x[mask] = np.array([0, 1, 0.5]) * t[mask]\n",
    "            plt.imsave(os.path.join(output_dir, 'res_{}_sample_{}_in.png'.format(2 ** lod, i)), x)\n",
    "\n",
    "            x_r = np.stack([x_out] * 3, axis=0).squeeze().transpose((1, 2, 0))\n",
    "            t_r = np.stack([t_out] * 3, axis=0).squeeze().transpose((1, 2, 0))\n",
    "            mask = t_r[..., 0] > self.iouThreshold\n",
    "            x_r[mask] = np.array([0, 1, 0.5]) * t[mask]\n",
    "            plt.imsave(os.path.join(output_dir, 'res_{}_sample_{}_out.png'.format(2 ** lod, i)), x_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a custom loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(output, x):\n",
    "    recon_x, mu, logVar = output\n",
    "    batchSize = mu.shape[0]\n",
    "    rl = (recon_x - x).pow(2).sum() / batchSize\n",
    "    kld = -0.5 * torch.sum(1 + logVar - mu.pow(2) - logVar.exp()) / batchSize\n",
    "    return rl + kld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Putting it all together\n",
    "We pass our custom datasets to pytorch dataloaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load(os.path.join(aug_data_dir,'unaugmented_chunk_1.pt'))\n",
    "test_data = torch.load(os.path.join(aug_data_dir,'unaugmented_chunk_2.pt'))\n",
    "\n",
    "batchSize = 64\n",
    "num_workers = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data, batch_size=batchSize,\n",
    "    shuffle=True, num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_data, batch_size=batchSize, \n",
    "    shuffle=True, num_workers=num_workers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VAE((1, d, d), 16, F.elu, False)\n",
    "\n",
    "test = Test(model=model,\n",
    "            dir=model_dir,\n",
    "            load=False, \n",
    "            optimizer=optim.Adam(model.parameters(), lr=0.001), \n",
    "            criterions=[loss_function, torch.nn.BCELoss()], \n",
    "            iouThreshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lod = 6\n",
    "iterations = 1\n",
    "\n",
    "for i in range(iterations):\n",
    "    test.train(train_loader, epochs, lod,1)\n",
    "    test.evaluate(test_loader, lod)\n",
    "    test.save_reconst(test_loader, lod, 10, output_dir)\n",
    "    #test.saveCheckpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9f82d0d752eb34e678ed91836faafc818af014405bd67d0435880e47f8c111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
