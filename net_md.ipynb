{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE-Segmentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through the process of creating a pytorch-compatible dataset, and setting up a model for segmentation of tumors in various organs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as U\n",
    "import torchvision.transforms as T\n",
    "from torch import Tensor\n",
    "import json\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Progress bar.\n",
    "import os\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if GPU is available and get some system stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "NVIDIA GeForce GTX 1070\n",
      "CUDA version: 11.7\n",
      "RAM: 16.74GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('CUDA version:', torch.version.cuda)\n",
    "\n",
    "available_ram = round(psutil.virtual_memory()[0]/1000000000,2)\n",
    "print('RAM: ' + str(available_ram) + 'GB')\n",
    "\n",
    "# Manual override:\n",
    "torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure we are in the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/nv/Storage/Data-Science/vae_lung_tumor_segmentation\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the location of the project's directory, in relation to the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_root_dir = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up some global constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "organs = ['spleen', 'colon', 'lung']\n",
    "d = 256 # New dimensions (width and height) of datapoints.\n",
    "\n",
    "# Data transform definitions.\n",
    "resize_transform = T.Resize((d, d))\n",
    "rand_rot_transform = T.RandomRotation(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load current progress, as to not repeat work, which has already been completed, when running the entire notebook at once. The progress is stored in `progression.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_file_path = f'{rel_root_dir}progression.json'\n",
    "with open(progress_file_path,'r') as f:\n",
    "    progression = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function which loads and stores our data in the proper formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(organ, training_paths, data_tensor, progress):\n",
    "    for _, path in enumerate(training_paths):\n",
    "        progress.set_postfix(**{'RAM':round(psutil.virtual_memory()[3]/1000000000,2)})\n",
    "        progress.update()\n",
    "\n",
    "        # Get path to images - removed dot in path from json-file.\n",
    "        nii_img = nib.load(f'{rel_root_dir}raw_data/{organ}' + path['image'][1:])\n",
    "        \n",
    "        nii_data = nii_img.get_fdata()\n",
    "        nii_data = Tensor(nii_img.get_fdata())\n",
    "        \n",
    "        # Ensure scale [0; 1]\n",
    "        nii_data -= nii_data.min()\n",
    "        nii_data /= nii_data.max() # Are the max the same in every data point?\n",
    "        nii_data = nii_data.permute(2, 0, 1) # Shape: (slice, rows, columns)\n",
    "        nii_data = resize_transform(nii_data)\n",
    "        data_tensor = torch.cat((data_tensor, nii_data), 0)\n",
    "        \n",
    "    torch.save(data_tensor, f'{rel_root_dir}augmented_data/{organ}_slices_unaugmented.pt')\n",
    "    progress.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process and format datasets from raw data for each organ, using the above function. We save progress after each organ is completed. Can be interrupted and resumed at any time, and accounts for progress, which has already been made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spleen set has already been loaded.\n",
      "The colon set has already been loaded.\n",
      "The lung set has already been loaded.\n"
     ]
    }
   ],
   "source": [
    "for organ in organs:\n",
    "    if not progression['loaded'][organ]:\n",
    "\n",
    "        path = f'{rel_root_dir}raw_data/{organ}/dataset.json'\n",
    "        with open(path) as f:\n",
    "            data_set = json.load(f)\n",
    "        training_paths = data_set['training']\n",
    "\n",
    "        data_tensor = torch.zeros((0, d, d))\n",
    "        total_paths = len(training_paths)\n",
    "\n",
    "        progress = tqdm(total=total_paths)\n",
    "        progress.set_description(f'%s' % organ)\n",
    "\n",
    "        try: \n",
    "            augment_data(organ, training_paths, data_tensor, progress)\n",
    "            print('The ' + organ + ' was successfully loaded.')\n",
    "\n",
    "            # Change state of progression.json\n",
    "            progression['loaded'][organ] = True\n",
    "            with open(progress_file_path, \"w\") as f: \n",
    "                json.dump(progression, f, indent=4)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print ('Manually stopped.\\nOrgan: ' + organ + ' was not saved.')\n",
    "            progress.close()\n",
    "            break\n",
    "    else:\n",
    "        print('The ' + organ + ' set has already been loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are so large, that we need to split them into smaller chunks. We first initialize empty chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = 10\n",
    "for n in range(num_chunks):\n",
    "    chunk = torch.zeros(0, d, d)\n",
    "    torch.save(chunk, f'augmented_data/unaugmented_chunk_{n}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fill them with augmented data from each organ, evenly split amongst the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation and chunking already completed.\n"
     ]
    }
   ],
   "source": [
    "if not progression['augmented']:\n",
    "    progress = tqdm(total=len(organs)*num_chunks)\n",
    "    progress.set_description(f'Augmentation')\n",
    "    \n",
    "    try:\n",
    "        for organ in organs:\n",
    "            data = torch.load(f'augmented_data/{organ}_slices_unaugmented.pt')\n",
    "            N = data.shape[0]\n",
    "            idx = torch.randperm(N)\n",
    "            data = data[idx]\n",
    "            split_idx = int(N/num_chunks)\n",
    "            \n",
    "            for n in range(num_chunks):\n",
    "                chunk = torch.load(f'augmented_data/unaugmented_chunk_{n}.pt')\n",
    "                chunk = torch.cat((chunk, data[n*split_idx:(n+1)*split_idx]), 0)\n",
    "                torch.save(chunk, f'augmented_data/unaugmented_chunk_{n}.pt')\n",
    "                progress.update()\n",
    "\n",
    "        print('Augmentation was successful.')\n",
    "\n",
    "        # Change state of progression.json\n",
    "        progression['augmented'] = True\n",
    "        with open(progress_file_path, \"w\") as f: \n",
    "            json.dump(progression, f, indent=4)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print ('Manually stopped.\\nChunk ' + str(n) + ' was not saved.')\n",
    "        progress.close()\n",
    "        \n",
    "else:\n",
    "    print('Data augmentation and chunking already completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a bunch of utility functions for checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_checkpoints(dir):\n",
    "    epochs = []\n",
    "    for name in os.listdir(dir):\n",
    "        if os.path.splitext(name)[-1] == '.pth':\n",
    "            epochs += [int(name.strip('ckpt_.pth'))]\n",
    "    return epochs\n",
    "\n",
    "def save_checkpoint(dir, epoch, model, optimizer=None):\n",
    "    checkpoint = {}; checkpoint['epoch'] = epoch\n",
    "\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        checkpoint['model'] = model.module.state_dict()\n",
    "    else:\n",
    "        checkpoint['model'] = model.state_dict()\n",
    "\n",
    "    if optimizer is not None:\n",
    "        checkpoint['optimizer'] = optimizer.state_dict()\n",
    "    else:\n",
    "        checkpoint['optimizer'] = None\n",
    "\n",
    "    torch.save(checkpoint, os.path.join(dir, 'ckpt_%02d.pth'% epoch))\n",
    "\n",
    "def load_checkpoint(dir, epoch=0):\n",
    "    if epoch == 0: epoch = max(list_checkpoints(dir))\n",
    "    checkpoint_path = os.path.join(dir, 'ckpt_%02d.pth'% epoch)\n",
    "    return torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "def load_model(dir, model, epoch=0):\n",
    "    ckpt = load_checkpoint(dir, epoch)\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model.module.load_state_dict(ckpt['model'])\n",
    "    else:\n",
    "        model.load_state_dict(ckpt['model'])\n",
    "    return model\n",
    "\n",
    "def load_optimizer(dir, optimizer, epoch=0):\n",
    "    ckpt = load_checkpoint(dir, epoch)\n",
    "    optimizer.load_state_dict(ckpt['optimizer'])\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9f82d0d752eb34e678ed91836faafc818af014405bd67d0435880e47f8c111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
