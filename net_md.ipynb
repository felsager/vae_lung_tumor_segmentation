{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE-Segmentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through the process of creating a pytorch-compatible dataset, and setting up a model for segmentation of tumors in various organs. It enables reproduceability of our final model and testing results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ML\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as U\n",
    "import torch.utils.data as D\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "\n",
    "# For reading raw data.\n",
    "import json\n",
    "import nibabel as nib\n",
    "\n",
    "# For displaying and evaluating results.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For monitoring resource-usage and progress.\n",
    "from tqdm import tqdm\n",
    "import os, psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if GPU is available and retrieve some system stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "NVIDIA GeForce GTX 1070\n",
      "CUDA version: 11.7\n",
      "RAM: 16.74GB\n"
     ]
    }
   ],
   "source": [
    "# Setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('CUDA version:', torch.version.cuda)\n",
    "\n",
    "available_ram = round(psutil.virtual_memory()[0]/1000000000,2)\n",
    "print('RAM: ' + str(available_ram) + 'GB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure, we are in the correct working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/nv/Storage/Data-Science/vae_lung_tumor_segmentation\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up some global constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of project directory, relative to the working directory.\n",
    "root_dir = './' \n",
    "\n",
    "# The organs, we wish our model to consider.\n",
    "organs = ['spleen', 'colon', 'lung']\n",
    "\n",
    "# New dimensions (width and height) of datapoints.\n",
    "d = 256 \n",
    "\n",
    "# Number of chunks to divide our data into.\n",
    "num_chunks = 10\n",
    "\n",
    "# Data transforms.\n",
    "resize_transform = T.Resize((d, d))\n",
    "rand_rot_transform = T.RandomRotation(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup a folder structure for our data - both raw and preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = root_dir + 'raw_data'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    for organ in organs:\n",
    "        os.mkdir(os.path.join(path, organ))\n",
    "        \n",
    "if not os.path.exists('augmented_data'):\n",
    "    os.makedirs('augmented_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `raw_data/` sub-directories for each organ has to be populated manually using the unzipped files from [medicaldecathlon.com](https://drive.google.com/drive/folders/1HqEgzS8BV2c7xYNrZdEAnrHk7osJJ--2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load current progress, as to not repeat work, which has already been completed, when running the entire notebook at once. The progress flags are stored externally in `progression.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_file_path = f'{root_dir}progression.json'\n",
    "with open(progress_file_path,'r') as f:\n",
    "    progression = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function which loads and stores our data in the proper formatting. As the datasets are huge, we monitor progress and RAM-usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(organ, training_paths, data_tensor, progress):\n",
    "    for _, path in enumerate(training_paths):\n",
    "        progress.set_postfix(**{'RAM':round(psutil.virtual_memory()[3]/1000000000,2)})\n",
    "        progress.update()\n",
    "\n",
    "        # Get path to images - removed dot in path from json-file.\n",
    "        nii_img = nib.load(f'{root_dir}raw_data/{organ}' + path['image'][1:])\n",
    "        \n",
    "        nii_data = nii_img.get_fdata()\n",
    "        nii_data = Tensor(nii_img.get_fdata())\n",
    "        \n",
    "        # Ensure scale [0; 1]\n",
    "        nii_data -= nii_data.min()\n",
    "        nii_data /= nii_data.max() # Are the max the same in every data point?\n",
    "        nii_data = nii_data.permute(2, 0, 1) # Shape: (slice, rows, columns)\n",
    "        nii_data = resize_transform(nii_data)\n",
    "        data_tensor = torch.cat((data_tensor, nii_data), 0)\n",
    "        \n",
    "    torch.save(data_tensor, f'{root_dir}augmented_data/{organ}_slices_unaugmented.pt')\n",
    "    progress.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process and format datasets from raw data for each organ, using the above function. We save progress after each organ is completed. Can be interrupted and resumed at any time, and accounts for progress, which has already been made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spleen set has already been loaded.\n",
      "The colon set has already been loaded.\n",
      "The lung set has already been loaded.\n"
     ]
    }
   ],
   "source": [
    "for organ in organs:\n",
    "    if not progression['loaded'][organ]:\n",
    "\n",
    "        path = f'{root_dir}raw_data/{organ}/dataset.json'\n",
    "        with open(path) as f:\n",
    "            data_set = json.load(f)\n",
    "        training_paths = data_set['training']\n",
    "\n",
    "        data_tensor = torch.zeros((0, d, d))\n",
    "        total_paths = len(training_paths)\n",
    "\n",
    "        progress = tqdm(total=total_paths)\n",
    "        progress.set_description(f'%s' % organ)\n",
    "\n",
    "        try: \n",
    "            augment_data(organ, training_paths, data_tensor, progress)\n",
    "            print('The ' + organ + ' was successfully loaded.')\n",
    "\n",
    "            # Change state of progression.json\n",
    "            progression['loaded'][organ] = True\n",
    "            with open(progress_file_path, \"w\") as f: \n",
    "                json.dump(progression, f, indent=4)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print ('Manually stopped.\\nOrgan: ' + organ + ' was not saved.')\n",
    "            progress.close()\n",
    "            break\n",
    "    else:\n",
    "        print('The ' + organ + ' set has already been loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets are so large, that we need to split them into smaller chunks. We first initialize empty chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(num_chunks):\n",
    "    chunk = torch.zeros(0, d, d)\n",
    "    torch.save(chunk, f'augmented_data/unaugmented_chunk_{n}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And fill them with augmented data from each organ, evenly split amongst the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation and chunking already completed.\n"
     ]
    }
   ],
   "source": [
    "if not progression['augmented']:\n",
    "    progress = tqdm(total=len(organs)*num_chunks)\n",
    "    progress.set_description(f'Augmentation')\n",
    "    \n",
    "    try:\n",
    "        for organ in organs:\n",
    "            data = torch.load(f'{root_dir}augmented_data/{organ}_slices_unaugmented.pt')\n",
    "            N = data.shape[0]\n",
    "            idx = torch.randperm(N)\n",
    "            data = data[idx]\n",
    "            split_idx = int(N/num_chunks)\n",
    "            \n",
    "            for n in range(num_chunks):\n",
    "                path = f'{root_dir}augmented_data/unaugmented_chunk_{n}.pt'\n",
    "                chunk = torch.load(path)\n",
    "                chunk = torch.cat((chunk, data[n*split_idx:(n+1)*split_idx]), 0)\n",
    "                torch.save(chunk, path)\n",
    "                progress.update()\n",
    "\n",
    "        print('Augmentation was successful.')\n",
    "\n",
    "        # Change state of progression.json\n",
    "        progression['augmented'] = True\n",
    "        with open(progress_file_path, \"w\") as f: \n",
    "            json.dump(progression, f, indent=4)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print ('Manually stopped.\\nChunk ' + str(n) + ' was not saved.')\n",
    "        progress.close()\n",
    "        \n",
    "else:\n",
    "    print('Data augmentation and chunking already completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a bunch of utility functions for checkpointing, as training on such large datapoints may require that we break up the training in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_checkpoints(dir):\n",
    "    epochs = []\n",
    "    for name in os.listdir(dir):\n",
    "        if os.path.splitext(name)[-1] == '.pth':\n",
    "            epochs += [int(name.strip('ckpt_.pth'))]\n",
    "    return epochs\n",
    "\n",
    "def save_checkpoint(dir, epoch, model, optimizer=None):\n",
    "    checkpoint = {}; checkpoint['epoch'] = epoch\n",
    "\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        checkpoint['model'] = model.module.state_dict()\n",
    "    else:\n",
    "        checkpoint['model'] = model.state_dict()\n",
    "\n",
    "    if optimizer is not None:\n",
    "        checkpoint['optimizer'] = optimizer.state_dict()\n",
    "    else:\n",
    "        checkpoint['optimizer'] = None\n",
    "\n",
    "    torch.save(checkpoint, os.path.join(dir, 'ckpt_%02d.pth'% epoch))\n",
    "\n",
    "def load_checkpoint(dir, epoch=0):\n",
    "    if epoch == 0: epoch = max(list_checkpoints(dir))\n",
    "    checkpoint_path = os.path.join(dir, 'ckpt_%02d.pth'% epoch)\n",
    "    return torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "def load_model(dir, model, epoch=0):\n",
    "    ckpt = load_checkpoint(dir, epoch)\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model.module.load_state_dict(ckpt['model'])\n",
    "    else:\n",
    "        model.load_state_dict(ckpt['model'])\n",
    "    return model\n",
    "\n",
    "def load_optimizer(dir, optimizer, epoch=0):\n",
    "    ckpt = load_checkpoint(dir, epoch)\n",
    "    optimizer.load_state_dict(ckpt['optimizer'])\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our model architecture for the variational autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 256\n",
    "w = h = 256 # output of encoder size.\n",
    "\n",
    "class VAEModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(VAEModel, self).__init__()\n",
    "        self.activation = nn.LeakyReLU(0.05)\n",
    "        self.encoder = nn.Sequential()\n",
    "        for i in range(0, 8):\n",
    "            self.encoder.append(nn.Sequential(\n",
    "                nn.Conv2d(2**i, 2**(i+1), 4, 2, 1),\n",
    "                #nn.BatchNorm2d(2**(i+1)),\n",
    "                self.activation,))\n",
    "\n",
    "        self.decoder = nn.Sequential()\n",
    "        for i in range(0, 7):\n",
    "            self.decoder.append(nn.Sequential(\n",
    "                nn.ConvTranspose2d(2**(8-i), 2**(7-i), 4, 2, 1),\n",
    "                #nn.BatchNorm2d(2**(7-i)),\n",
    "                self.activation,))\n",
    "        self.decoder.append(nn.Sequential(\n",
    "            nn.ConvTranspose2d(2, 1, kernel_size = 4, stride = 2, padding=1),\n",
    "            #nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.fc_mu = nn.Linear(w, latent_size)\n",
    "        self.fc_log_sigma = nn.Linear(w, latent_size)\n",
    "        self.latent_de = nn.Linear(latent_size, w)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        h = h.view(-1, w)\n",
    "        mu = self.fc_mu(h)\n",
    "        log_sigma = self.fc_log_sigma(h)\n",
    "        return mu, log_sigma\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = z.view(-1, w, 1, 1)\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def reparameterize(self, mu, log_sigma):\n",
    "        std = torch.exp(0.5*log_sigma)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, w, h) # Adds channel dimension.\n",
    "        mu, log_sigma = self.encode(x) # Log sigma is more stable (numerically).\n",
    "        z = self.reparameterize(mu, log_sigma)\n",
    "        z = self.latent_de(z)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat.view(-1, w, h), mu, log_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check if the model output dimensions make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 256, 256]), torch.Size([10, 256]), torch.Size([10, 256]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAEModel()\n",
    "A = torch.randn((10, 256, 256))\n",
    "B, mu_B, log_sigma_B = model.forward(A)\n",
    "B.shape, mu_B.shape, log_sigma_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a loss function, which will compare actual data to the data, we reconstruct with the variational autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_norm = 0.00390625\n"
     ]
    }
   ],
   "source": [
    "mse_loss = nn.MSELoss(reduction='mean')\n",
    "bce_loss = nn.BCELoss(reduction='mean')\n",
    "beta = 1; N = w*h; M = w; beta_norm = beta*M/N\n",
    "print(f'{beta_norm = }')\n",
    "\n",
    "def loss_fn(x, x_hat, mu, log_var): # input, reconstructed input    \n",
    "    BCE = bce_loss(x_hat, x) # MSE = mse_loss(x_hat, x)\n",
    "\n",
    "    # KL divergence.\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    KLD = KLD.mean() # Batch average.\n",
    "    loss = BCE + 0.000001*KLD # beta_norm*KLD # ELBO loss with beta_norm=0.1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function for drawing a datapoint along with its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(x, x_hat):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8,5))\n",
    "    img_0 = x[0].detach().numpy()\n",
    "    img_1 = x_hat[0].detach().numpy()\n",
    "    #img = img.reshape((-1, 28, 28)).transpose((1, 0, 2)).reshape(-1, 10*28)\n",
    "    #img = img * 0.3081 + 0.1307\n",
    "    axs[0].imshow(img_0, vmin=0, vmax=1, cmap='gray')\n",
    "    axs[1].imshow(img_1, vmin=0, vmax=1, cmap='gray')\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_loader(idx):\n",
    "    batch_size = 256\n",
    "    train_data = torch.load(f'{root_dir}augmented_data/unaugmented_chunk_{idx}.pt')\n",
    "    train_loader = D.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dev_loader():\n",
    "    batch_size = 256\n",
    "    dev_data = torch.load(f'{root_dir}augmented_data/unaugmented_chunk_{9}.pt')\n",
    "    dev_loader = D.DataLoader(dev_data, batch_size=batch_size, shuffle=True)\n",
    "    return dev_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders_2():\n",
    "    batch_size = 64\n",
    "    data = torch.load(f'{root_dir}augmented_data/data_chunk_unaugmented.pt')\n",
    "    #zero_imgs = torch.zeros((int(data.shape[0]/8), 256, 256)) # regularization data\n",
    "    #minus_one_imgs = -torch.ones((int(data.shape[0]/8), 256, 256)) # regularization data\n",
    "    #data = torch.cat((data, zero_imgs, one_imgs), dim=0)\n",
    "    #data = torch.cat((data, minus_one_imgs), dim=0)\n",
    "    N = len(data)\n",
    "    N_t = int(0.9*N)\n",
    "    N_d = N - N_t\n",
    "    train_data, dev_data = D.random_split(data, [N_t, N_d])\n",
    "    train_loader = D.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    dev_loader = D.DataLoader(dev_data, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, dev_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We move our model to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for i in torch.randperm(10):\n",
    "        i = int(i)\n",
    "        train_loader = make_train_loader(i)\n",
    "        for x in train_loader:\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_hat, mu, log_var = model.forward(x)\n",
    "            loss = loss_fn(x, x_hat, mu, log_var)\n",
    "            loss.backward()\n",
    "            # plot_grad_flow(model.named_parameters())\n",
    "            optimizer.step()\n",
    "            losses += loss.item()\n",
    "    loader_length = num_chunks*len(train_loader) # 10 chunks\n",
    "    return losses / (loader_length)  # average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dev_loader):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    for x in dev_loader:\n",
    "        x = x.to(device)\n",
    "        x_hat, mu, log_var = model.forward(x)\n",
    "        loss = loss_fn(x, x_hat, mu, log_var)\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "dev_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('../saved_models/model_13')\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 1000\n",
    "\n",
    "#train_loader, dev_loader = make_loaders()\n",
    "#train_loader, dev_loader = make_loaders_2()\n",
    "dev_loader = make_dev_loader()\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(model, optimizer)\n",
    "    train_losses.append(train_loss)\n",
    "    end_time = timer()\n",
    "    dev_loss = evaluate(model, dev_loader)\n",
    "    dev_losses.append(dev_loss)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Dev loss: {dev_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, f'{root_dir}saved_models/model_22')\n",
    "torch.save(torch.Tensor(train_losses), f'{root_dir}losses/train_losses_model_22')\n",
    "torch.save(torch.Tensor(dev_losses), f'{root_dir}losses/dev_losses_model_22')\n",
    "dev_losses_2 = torch.load(f'{root_dir}losses/dev_losses_model_15')\n",
    "print(dev_losses_2[-1], dev_losses[-1])\n",
    "print(len(dev_losses_2), len(dev_losses))\n",
    "plt.plot((dev_losses_2))\n",
    "plt.plot((dev_losses))\n",
    "plt.xlim([80, 120])\n",
    "plt.ylim([0.303, 0.306])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x_test = next(iter(dev_loader))[0].view(1, 256, 256).to(device)\n",
    "#x_test = torch.zeros((1, 256, 256)).to(device)\n",
    "x_hat_test = model.forward(x_test)[0]\n",
    "draw(x_test.cpu(), x_hat_test.cpu())\n",
    "mse_loss(x_test, x_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x_sampled = model.decode(torch.randn(1, latent_size).to(device)).view(1, 256, 256).cpu()\n",
    "plt.imshow(x_sampled[0].detach().numpy(), vmin=0, vmax=1, cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9f82d0d752eb34e678ed91836faafc818af014405bd67d0435880e47f8c111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
