{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE-Segmentation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook goes through the process of creating a pytorch-compatible dataset, and setting up a model for segmentation of tumors in various organs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.utils as U\n",
    "import torchvision.transforms as T\n",
    "from torch import Tensor\n",
    "import json\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm # Progress bar.\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure we are in the correct directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/nv/Storage/Data-Science/vae_lung_tumor_segmentation\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the location of the project's directory, in relation to the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_root_dir = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up some global constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "organs = ['spleen', 'colon', 'lung']\n",
    "d = 256 # New dimensions (width and height) of datapoints.\n",
    "\n",
    "# Data transform definitions.\n",
    "resize_transform = T.Resize((d, d))\n",
    "rand_rot_transform = T.RandomRotation(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load current progress, as to not repeat work, which has already been completed, when running the entire notebook at once. The progress is stored in `progression.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_file_path = f'{rel_root_dir}progression.json'\n",
    "with open(progress_file_path,'r') as f:\n",
    "    progression = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function which loads and stores our data in the proper formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(organ, training_paths, data_tensor, progress):\n",
    "    for path in enumerate(training_paths):\n",
    "        progress.update()\n",
    "\n",
    "        # Get path to images - removed dot in path from json-file.\n",
    "        nii_img = nib.load(f'{rel_root_dir}raw_data/{organ}' + path['image'][1:])\n",
    "        nii_data = nii_img.get_fdata()\n",
    "        nii_data = Tensor(nii_img.get_fdata())\n",
    "        \n",
    "        # Ensure scale [0; 1]\n",
    "        nii_data -= nii_data.min()\n",
    "        nii_data /= nii_data.max() # Are the max the same in every data point?\n",
    "        nii_data = nii_data.permute(2, 0, 1) # Shape: (slice, rows, columns)\n",
    "        nii_data = resize_transform(nii_data)\n",
    "        data_tensor = torch.cat((data_tensor, nii_data), 0)\n",
    "        \n",
    "    torch.save(data_tensor, f'{rel_root_dir}augmented_data/{organ}_slices_unaugmented.pt')\n",
    "    progress.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate and save augmented dataset from raw data for each organ, using the above function. We save progress after each organ is completed. Can be interrupted and resumed at any time, and accounts for progress, which has already been made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spleen set has already been loaded.\n",
      "The colon set has already been loaded.\n",
      "The lung set has already been loaded.\n"
     ]
    }
   ],
   "source": [
    "for organ in organs:\n",
    "    if not progression['loaded'][organ]:\n",
    "\n",
    "        path = f'{rel_root_dir}raw_data/{organ}/dataset.json'\n",
    "        with open(path) as f:\n",
    "            data_set = json.load(f)\n",
    "        training_paths = data_set['training']\n",
    "\n",
    "        data_tensor = torch.zeros((0, d, d))\n",
    "        total_paths = len(training_paths)\n",
    "\n",
    "        progress = tqdm(total=total_paths)\n",
    "        progress.set_description(f'%s' % organ)\n",
    "\n",
    "        try: \n",
    "            augment_data(organ, training_paths, data_tensor, progress)\n",
    "            print('The ' + organ + 'successfully loaded.')\n",
    "\n",
    "            # Change state of progression.json\n",
    "            progression['loaded'][organ] = True\n",
    "            with open(progress_file_path, \"w\") as f: \n",
    "                json.dump(progression, f, indent=4)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print ('Manually stopped.\\nOrgan: ' + organ + ' was not saved.')\n",
    "            progress.close()\n",
    "            break\n",
    "    else:\n",
    "        print('The ' + organ + ' set has already been loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a bunch of utility functions for checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_checkpoints(dir):\n",
    "    epochs = []\n",
    "    for name in os.listdir(dir):\n",
    "        if os.path.splitext(name)[-1] == '.pth':\n",
    "            epochs += [int(name.strip('ckpt_.pth'))]\n",
    "    return epochs\n",
    "\n",
    "def save_checkpoint(dir, epoch, model, optimizer=None):\n",
    "    checkpoint = {}; checkpoint['epoch'] = epoch\n",
    "\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        checkpoint['model'] = model.module.state_dict()\n",
    "    else:\n",
    "        checkpoint['model'] = model.state_dict()\n",
    "\n",
    "    if optimizer is not None:\n",
    "        checkpoint['optimizer'] = optimizer.state_dict()\n",
    "    else:\n",
    "        checkpoint['optimizer'] = None\n",
    "\n",
    "    torch.save(checkpoint, os.path.join(dir, 'ckpt_%02d.pth'% epoch))\n",
    "\n",
    "def load_checkpoint(dir, epoch=0):\n",
    "    if epoch == 0: epoch = max(list_checkpoints(dir))\n",
    "    checkpoint_path = os.path.join(dir, 'ckpt_%02d.pth'% epoch)\n",
    "    return torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "def load_model(dir, model, epoch=0):\n",
    "    ckpt = load_checkpoint(dir, epoch)\n",
    "    if isinstance(model, torch.nn.DataParallel):\n",
    "        model.module.load_state_dict(ckpt['model'])\n",
    "    else:\n",
    "        model.load_state_dict(ckpt['model'])\n",
    "    return model\n",
    "\n",
    "def load_optimizer(dir, optimizer, epoch=0):\n",
    "    ckpt = load_checkpoint(dir, epoch)\n",
    "    optimizer.load_state_dict(ckpt['optimizer'])\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b9f82d0d752eb34e678ed91836faafc818af014405bd67d0435880e47f8c111"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
